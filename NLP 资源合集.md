## NLP 资源合集

### Useful GitHub Reading List

- https://github.com/iwangjian/Paper-Reading :star::star::star::star::star:
- https://github.com/crownpku/Awesome-Chinese-NLP (中文自然语言处理相关资料) :star::star::star: 
- https://github.com/shaoxiongji/awesome-knowledge-graph (A collection of knowledge graph papers and reading notes) :star::star::star:
- https://github.com/IsaacChanghau/DL-NLP-Readings :star::star::star::star: 


### 预训练模型 [[Ref](https://mp.weixin.qq.com/s/8_UZeAUtBElaO9aY5iSo-g)]

**Cove：《Learned in Translation: Contextualized Word Vectors》**

Pytoch：https://github.com/salesforce/cove

Keras：https://github.com/rgsachin/CoVe

**ULMFit：《Universal Language Model Fine-tuning for Text Classification》** [[Paper](https://arxiv.org/abs/1801.06146)] [[PyTorch](https://github.com/fastai/fastai/tree/ulmfit_v1)]

**ELMO：《Deep contextualized word representations》** [[Paper](https://arxiv.org/pdf/1802.05365.pdf
)]

PyTorch：https://github.com/allenai/allennlp

TensorFlow：https://github.com/allenai/bilm-tf

**GPT-1：《Improving Language Understanding by Generative Pre-Training》**

PyTorch：https://github.com/huggingface/pytorch-openai-transformer-lm

TensorFlow：https://github.com/openai/finetune-transformer-lm

**Bert：《BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding》** [[Paper](https://arxiv.org/pdf/1810.04805.pdf)]

PyTorch：https://github.com/huggingface/pytorch-pretrained-BERT

TensorFlow：https://github.com/google-research/bert

**Transformer-XL：《Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context》** [[Paper](https://arxiv.org/abs/1901.02860)]

PyTorch：https://github.com/kimiyoung/transformer-xl/tree/master/tf

TensorFlow：https://github.com/kimiyoung/transformer-xl/tree/master/pytorch

**XLM：《Cross-lingual Language Model Pretraining》**

PyTorch：https://github.com/facebookresearch/XLM

**GPT-2：《Language Models are Unsupervised Multitask Learners》**

TensorFlow：https://github.com/openai/gpt-2
